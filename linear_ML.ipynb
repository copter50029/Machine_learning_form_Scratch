{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data set (house_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "print(housing.data.shape, housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup']\n"
     ]
    }
   ],
   "source": [
    "print(housing.feature_names[0:6])# we don't need latitude and longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedHouseVal']\n"
     ]
    }
   ],
   "source": [
    "print(housing.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - `x_train` is the x label (['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x_train: <class 'numpy.ndarray'>\n",
      "Shape of x_train: (20640, 6)\n",
      "[[8.32520000e+00 4.10000000e+01 6.98412698e+00 1.02380952e+00\n",
      "  3.22000000e+02 2.55555556e+00]\n",
      " [8.30140000e+00 2.10000000e+01 6.23813708e+00 9.71880492e-01\n",
      "  2.40100000e+03 2.10984183e+00]\n",
      " [7.25740000e+00 5.20000000e+01 8.28813559e+00 1.07344633e+00\n",
      "  4.96000000e+02 2.80225989e+00]\n",
      " [5.64310000e+00 5.20000000e+01 5.81735160e+00 1.07305936e+00\n",
      "  5.58000000e+02 2.54794521e+00]\n",
      " [3.84620000e+00 5.20000000e+01 6.28185328e+00 1.08108108e+00\n",
      "  5.65000000e+02 2.18146718e+00]\n",
      " [4.03680000e+00 5.20000000e+01 4.76165803e+00 1.10362694e+00\n",
      "  4.13000000e+02 2.13989637e+00]\n",
      " [3.65910000e+00 5.20000000e+01 4.93190661e+00 9.51361868e-01\n",
      "  1.09400000e+03 2.12840467e+00]\n",
      " [3.12000000e+00 5.20000000e+01 4.79752705e+00 1.06182380e+00\n",
      "  1.15700000e+03 1.78825348e+00]\n",
      " [2.08040000e+00 4.20000000e+01 4.29411765e+00 1.11764706e+00\n",
      "  1.20600000e+03 2.02689076e+00]]\n"
     ]
    }
   ],
   "source": [
    "x_label = housing.data[0::, 0:6] # the first [] is specifly W and second one are column\n",
    "print(\"Type of x_train:\", type(x_label))\n",
    "print(\"Shape of x_train:\", x_label.shape)\n",
    "print(x_label[0:9])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - `Y_train` is the house price (in 100k unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of x_train: <class 'numpy.ndarray'>\n",
      "Shape of x_train: (20640,)\n",
      "[4.526]\n"
     ]
    }
   ],
   "source": [
    "y_label = housing.target\n",
    "print(\"Type of x_train:\", type(y_label))\n",
    "print(\"Shape of x_train:\", y_label.shape)\n",
    "print(y_label[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the dimensions of your variables\n",
    "\n",
    "Another useful way to get familiar with your data is to view its dimensions.\n",
    "\n",
    "print the shape of `x_train` and `y_train` to see how many training examples i have in my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_label is: (20640, 6)\n",
      "The shape of y_label is:  (20640,)\n",
      "Number of label examples (m): 20640\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of x_label is:', x_label.shape)\n",
    "print ('The shape of y_label is: ', y_label.shape)\n",
    "print ('Number of label examples (m):', len(x_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.32520000e+00 4.10000000e+01 6.98412698e+00 1.02380952e+00\n",
      "  3.22000000e+02 2.55555556e+00]\n",
      " [8.30140000e+00 2.10000000e+01 6.23813708e+00 9.71880492e-01\n",
      "  2.40100000e+03 2.10984183e+00]\n",
      " [7.25740000e+00 5.20000000e+01 8.28813559e+00 1.07344633e+00\n",
      "  4.96000000e+02 2.80225989e+00]\n",
      " ...\n",
      " [1.70000000e+00 1.70000000e+01 5.20554273e+00 1.12009238e+00\n",
      "  1.00700000e+03 2.32563510e+00]\n",
      " [1.86720000e+00 1.80000000e+01 5.32951289e+00 1.17191977e+00\n",
      "  7.41000000e+02 2.12320917e+00]\n",
      " [2.38860000e+00 1.60000000e+01 5.25471698e+00 1.16226415e+00\n",
      "  1.38700000e+03 2.61698113e+00]]\n",
      "[[4.526]\n",
      " [3.585]\n",
      " [3.521]\n",
      " ...\n",
      " [0.923]\n",
      " [0.847]\n",
      " [0.894]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = np.array(x_label, dtype=float)\n",
    "X_train = X_train.ravel().reshape(-1, 6)\n",
    "y_train = np.array(y_label, dtype=float)\n",
    "y_train = y_train.ravel().reshape(-1, 1)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x,y,w,b):\n",
    "    m = x.shape[0]\n",
    "\n",
    "    cost = 0 \n",
    "\n",
    "    for i in range(m):\n",
    "        f_w = w*x[i] + b\n",
    "        cost = cost + (f_w - y[i])**2\n",
    "    j_w = (1 / 2*m) * cost # totalcost\n",
    "    return j_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2.3\"></a>\n",
    "### compute_gradient\n",
    "<a name='ex-01'></a>\n",
    "`compute_gradient`  implements (4) and (5) above and returns $\\frac{\\partial J(w,b)}{\\partial w}$,$\\frac{\\partial J(w,b)}{\\partial b}$. The embedded comments describe the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b): \n",
    "    m,n = X.shape \n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0 \n",
    "    \n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math , copy\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \n",
    "    \n",
    "    # number of training examples\n",
    "    m = len(X)\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration â€” primarily for graphing later\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_dw, dj_db = gradient_function(X, y, w, b )  \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               \n",
    "        b = b - alpha * dj_db               \n",
    "\n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            cost =  cost_function(x, y, w, b)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters/10) == 0:\n",
    "            w_history.append(w)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history, w_history #return w and J,w history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1500\u001b[39m\n\u001b[0;32m      7\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m----> 9\u001b[0m w,b,_,_ \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcompute_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw,b found by gradient descent:\u001b[39m\u001b[38;5;124m\"\u001b[39m, w, b)\n",
      "Cell \u001b[1;32mIn[134], line 17\u001b[0m, in \u001b[0;36mgradient_descent\u001b[1;34m(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters)\u001b[0m\n\u001b[0;32m     12\u001b[0m b \u001b[38;5;241m=\u001b[39m b_in\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iters):\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Calculate the gradient and update the parameters\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     dj_dw, dj_db \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Update Parameters using w, b, alpha and gradient\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     w \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m-\u001b[39m alpha \u001b[38;5;241m*\u001b[39m dj_dw               \n",
      "Cell \u001b[1;32mIn[133], line 9\u001b[0m, in \u001b[0;36mcompute_gradient\u001b[1;34m(X, y, w, b)\u001b[0m\n\u001b[0;32m      7\u001b[0m     err \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mdot(X[i], w) \u001b[38;5;241m+\u001b[39m b) \u001b[38;5;241m-\u001b[39m y[i]   \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):                         \n\u001b[1;32m----> 9\u001b[0m         \u001b[43mdj_dw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m dj_dw[j] \u001b[38;5;241m+\u001b[39m err \u001b[38;5;241m*\u001b[39m X[i, j]    \n\u001b[0;32m     10\u001b[0m     dj_db \u001b[38;5;241m=\u001b[39m dj_db \u001b[38;5;241m+\u001b[39m err                        \n\u001b[0;32m     11\u001b[0m dj_dw \u001b[38;5;241m=\u001b[39m dj_dw \u001b[38;5;241m/\u001b[39m m                                \n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# initialize fitting parameters. Recall that the shape of w is (n,)\n",
    "initial_w = 0.\n",
    "initial_b = 0.\n",
    "\n",
    "# some gradient descent settings\n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "\n",
    "w,b,_,_ = gradient_descent(X_train ,y_train, initial_w, initial_b, \n",
    "                     compute_cost, compute_gradient, alpha, iterations)\n",
    "print(\"w,b found by gradient descent:\", w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myevm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
